{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier in PySpark - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction  \n",
    "\n",
    "In this lab, we would like to a Random Forest Classifier model to study over the ecommerce behavior from a multi-category store. First, we need to download the data to your local machine, then we will load the data from the local machine onto a Pandas Dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives  \n",
    "\n",
    "* Use the kaggle eCommerce dataset in the previous lab and reimplement using PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruction\n",
    "* Accept the kaggle policy and download the data from here https://www.kaggle.com/code/tshephisho/ecommerce-behaviour-using-xgboost/data\n",
    "* For the first model building, we'll only use the 2019-Nov csv data (which is still around ~2gb zipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting squarify\n",
      "  Downloading squarify-0.4.3-py3-none-any.whl (4.3 kB)\n",
      "Installing collected packages: squarify\n",
      "Successfully installed squarify-0.4.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install squarify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import squarify\n",
    "import matplotlib.dates as dates\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession #entry point for pyspark\n",
    "\n",
    "#instantiate spark instance\n",
    "spark = SparkSession.builder.appName('Random Forest eCommerce').master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event_time: string (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- category_id: long (nullable = true)\n",
      " |-- category_code: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- user_session: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"C:\\Flatiron\\Test.csv\" #wherever path you saved the kaggle file to\n",
    "df = spark.read.csv(path, header=True, inferSchema=True)\n",
    "df.printSchema() #to see the schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've already used this dataset, but feel free to explore around. Now, we want to use the pandas instead of pyspark, we have to use the `action` functions, which then means there will be a network shuffle. Earlier lab used the Iris dataset which was about ~1KB, but the current dataset may be too large, and may throw an `OutOfMemory` error if we attempt to load the data into the pandas dataframe. I would suggest only take few rows for exploratory analysis if pandas is more comfortable library. Otherwise, sticking with native PySpark functions would be much better option. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>event_time</th>\n",
       "      <td>2019-11-01 00:00:00 UTC</td>\n",
       "      <td>2019-11-01 00:00:00 UTC</td>\n",
       "      <td>2019-11-01 00:00:01 UTC</td>\n",
       "      <td>2019-11-01 00:00:01 UTC</td>\n",
       "      <td>2019-11-01 00:00:01 UTC</td>\n",
       "      <td>2019-11-01 00:00:01 UTC</td>\n",
       "      <td>2019-11-01 00:00:01 UTC</td>\n",
       "      <td>2019-11-01 00:00:02 UTC</td>\n",
       "      <td>2019-11-01 00:00:02 UTC</td>\n",
       "      <td>2019-11-01 00:00:02 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event_type</th>\n",
       "      <td>view</td>\n",
       "      <td>view</td>\n",
       "      <td>view</td>\n",
       "      <td>view</td>\n",
       "      <td>view</td>\n",
       "      <td>view</td>\n",
       "      <td>view</td>\n",
       "      <td>view</td>\n",
       "      <td>view</td>\n",
       "      <td>view</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_id</th>\n",
       "      <td>1003461</td>\n",
       "      <td>5000088</td>\n",
       "      <td>17302664</td>\n",
       "      <td>3601530</td>\n",
       "      <td>1004775</td>\n",
       "      <td>1306894</td>\n",
       "      <td>1306421</td>\n",
       "      <td>15900065</td>\n",
       "      <td>12708937</td>\n",
       "      <td>1004258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category_id</th>\n",
       "      <td>2053013555631882655</td>\n",
       "      <td>2053013566100866035</td>\n",
       "      <td>2053013553853497655</td>\n",
       "      <td>2053013563810775923</td>\n",
       "      <td>2053013555631882655</td>\n",
       "      <td>2053013558920217191</td>\n",
       "      <td>2053013558920217191</td>\n",
       "      <td>2053013558190408249</td>\n",
       "      <td>2053013553559896355</td>\n",
       "      <td>2053013555631882655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category_code</th>\n",
       "      <td>electronics.smartphone</td>\n",
       "      <td>appliances.sewing_machine</td>\n",
       "      <td>None</td>\n",
       "      <td>appliances.kitchen.washer</td>\n",
       "      <td>electronics.smartphone</td>\n",
       "      <td>computers.notebook</td>\n",
       "      <td>computers.notebook</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>electronics.smartphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand</th>\n",
       "      <td>xiaomi</td>\n",
       "      <td>janome</td>\n",
       "      <td>creed</td>\n",
       "      <td>lg</td>\n",
       "      <td>xiaomi</td>\n",
       "      <td>hp</td>\n",
       "      <td>hp</td>\n",
       "      <td>rondell</td>\n",
       "      <td>michelin</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>489.07</td>\n",
       "      <td>293.65</td>\n",
       "      <td>28.31</td>\n",
       "      <td>712.87</td>\n",
       "      <td>183.27</td>\n",
       "      <td>360.09</td>\n",
       "      <td>514.56</td>\n",
       "      <td>30.86</td>\n",
       "      <td>72.72</td>\n",
       "      <td>732.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <td>520088904</td>\n",
       "      <td>530496790</td>\n",
       "      <td>561587266</td>\n",
       "      <td>518085591</td>\n",
       "      <td>558856683</td>\n",
       "      <td>520772685</td>\n",
       "      <td>514028527</td>\n",
       "      <td>518574284</td>\n",
       "      <td>532364121</td>\n",
       "      <td>532647354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_session</th>\n",
       "      <td>4d3b30da-a5e4-49df-b1a8-ba5943f1dd33</td>\n",
       "      <td>8e5f4f83-366c-4f70-860e-ca7417414283</td>\n",
       "      <td>755422e7-9040-477b-9bd2-6a6e8fd97387</td>\n",
       "      <td>3bfb58cd-7892-48cc-8020-2f17e6de6e7f</td>\n",
       "      <td>313628f1-68b8-460d-84f6-cec7a8796ef2</td>\n",
       "      <td>816a59f3-f5ae-4ccd-9b23-82aa8c23d33c</td>\n",
       "      <td>df8184cc-3694-4549-8c8c-6b5171877376</td>\n",
       "      <td>5e6ef132-4d7c-4730-8c7f-85aa4082588f</td>\n",
       "      <td>0a899268-31eb-46de-898d-09b2da950b24</td>\n",
       "      <td>d2d3d2c6-631d-489e-9fb5-06f340b85be0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  0  \\\n",
       "event_time                  2019-11-01 00:00:00 UTC   \n",
       "event_type                                     view   \n",
       "product_id                                  1003461   \n",
       "category_id                     2053013555631882655   \n",
       "category_code                electronics.smartphone   \n",
       "brand                                        xiaomi   \n",
       "price                                        489.07   \n",
       "user_id                                   520088904   \n",
       "user_session   4d3b30da-a5e4-49df-b1a8-ba5943f1dd33   \n",
       "\n",
       "                                                  1  \\\n",
       "event_time                  2019-11-01 00:00:00 UTC   \n",
       "event_type                                     view   \n",
       "product_id                                  5000088   \n",
       "category_id                     2053013566100866035   \n",
       "category_code             appliances.sewing_machine   \n",
       "brand                                        janome   \n",
       "price                                        293.65   \n",
       "user_id                                   530496790   \n",
       "user_session   8e5f4f83-366c-4f70-860e-ca7417414283   \n",
       "\n",
       "                                                  2  \\\n",
       "event_time                  2019-11-01 00:00:01 UTC   \n",
       "event_type                                     view   \n",
       "product_id                                 17302664   \n",
       "category_id                     2053013553853497655   \n",
       "category_code                                  None   \n",
       "brand                                         creed   \n",
       "price                                         28.31   \n",
       "user_id                                   561587266   \n",
       "user_session   755422e7-9040-477b-9bd2-6a6e8fd97387   \n",
       "\n",
       "                                                  3  \\\n",
       "event_time                  2019-11-01 00:00:01 UTC   \n",
       "event_type                                     view   \n",
       "product_id                                  3601530   \n",
       "category_id                     2053013563810775923   \n",
       "category_code             appliances.kitchen.washer   \n",
       "brand                                            lg   \n",
       "price                                        712.87   \n",
       "user_id                                   518085591   \n",
       "user_session   3bfb58cd-7892-48cc-8020-2f17e6de6e7f   \n",
       "\n",
       "                                                  4  \\\n",
       "event_time                  2019-11-01 00:00:01 UTC   \n",
       "event_type                                     view   \n",
       "product_id                                  1004775   \n",
       "category_id                     2053013555631882655   \n",
       "category_code                electronics.smartphone   \n",
       "brand                                        xiaomi   \n",
       "price                                        183.27   \n",
       "user_id                                   558856683   \n",
       "user_session   313628f1-68b8-460d-84f6-cec7a8796ef2   \n",
       "\n",
       "                                                  5  \\\n",
       "event_time                  2019-11-01 00:00:01 UTC   \n",
       "event_type                                     view   \n",
       "product_id                                  1306894   \n",
       "category_id                     2053013558920217191   \n",
       "category_code                    computers.notebook   \n",
       "brand                                            hp   \n",
       "price                                        360.09   \n",
       "user_id                                   520772685   \n",
       "user_session   816a59f3-f5ae-4ccd-9b23-82aa8c23d33c   \n",
       "\n",
       "                                                  6  \\\n",
       "event_time                  2019-11-01 00:00:01 UTC   \n",
       "event_type                                     view   \n",
       "product_id                                  1306421   \n",
       "category_id                     2053013558920217191   \n",
       "category_code                    computers.notebook   \n",
       "brand                                            hp   \n",
       "price                                        514.56   \n",
       "user_id                                   514028527   \n",
       "user_session   df8184cc-3694-4549-8c8c-6b5171877376   \n",
       "\n",
       "                                                  7  \\\n",
       "event_time                  2019-11-01 00:00:02 UTC   \n",
       "event_type                                     view   \n",
       "product_id                                 15900065   \n",
       "category_id                     2053013558190408249   \n",
       "category_code                                  None   \n",
       "brand                                       rondell   \n",
       "price                                         30.86   \n",
       "user_id                                   518574284   \n",
       "user_session   5e6ef132-4d7c-4730-8c7f-85aa4082588f   \n",
       "\n",
       "                                                  8  \\\n",
       "event_time                  2019-11-01 00:00:02 UTC   \n",
       "event_type                                     view   \n",
       "product_id                                 12708937   \n",
       "category_id                     2053013553559896355   \n",
       "category_code                                  None   \n",
       "brand                                      michelin   \n",
       "price                                         72.72   \n",
       "user_id                                   532364121   \n",
       "user_session   0a899268-31eb-46de-898d-09b2da950b24   \n",
       "\n",
       "                                                  9  \n",
       "event_time                  2019-11-01 00:00:02 UTC  \n",
       "event_type                                     view  \n",
       "product_id                                  1004258  \n",
       "category_id                     2053013555631882655  \n",
       "category_code                electronics.smartphone  \n",
       "brand                                         apple  \n",
       "price                                        732.07  \n",
       "user_id                                   532647354  \n",
       "user_session   d2d3d2c6-631d-489e-9fb5-06f340b85be0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " pd.DataFrame(df.take(10), columns=df.columns).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Know your Customers\n",
    "\n",
    "How many unique customers visit the site?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|count(DISTINCT user_id)|\n",
      "+-----------------------+\n",
      "|                3696117|\n",
      "+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using naitve pyspark..\n",
    "from pyspark.sql.functions import countDistinct\n",
    "df.select(countDistinct(\"user_id\")).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'About 3696117 users'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"About 3696117 users\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice the spark progress bar when you triggered the `action` function? The `show()` function is the `action` function which means the lazy evaluation of Spark was triggered and completed a certain job. `read.csv` should have been another job. If you go to the `localhost:4040` you should be able to see 2 completed jobs under the `Jobs` tab, which are `csv` and `showString`. While a heavy job is getting executed, you can take a look at the `Executors` tab to examine the executors completing the tasks in parellel. Now, we may not see if we run this on a local machine, but this behavior should definitely be visible if you're on a cloud system, such as EMR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Visitors Daily Trend\n",
    "\n",
    "Does traffic flunctuate by date? Try using the event_time and user_id to see traffic, and draw out the plots for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try cleaning out the event_time column then using groupby/count\n",
    "# import pyspark.sql.functions as F\n",
    "# use this as a reference to clean the event_time column\n",
    "# https://stackoverflow.com/questions/67827631/how-udf-function-works-in-pyspark-with-dates-as-arguments "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: We would still like to see the cart abandonment rate using the dataset. What relevant features can we use for modeling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's build out the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "#columns you'd like to use\n",
    "feature_cols = []\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "df = assembler.transform(df)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a labeler column that we'd like to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "#what should we use for the inputCol here?\n",
    "labeler = StringIndexer(inputCol='', outputCol='encoded')\n",
    "df = labeler.fit(df).transform(df)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build the train/test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df.randomSplit([0.7, 0.3], seed=42)\n",
    "print(\"Training Dataset Count: \" + str(train.count()))\n",
    "print(\"Test Dataset Count: \" + str(test.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol='', labelCol='encoded')\n",
    "model = rf.fit(train)\n",
    "predictions = model.transform(test)\n",
    "# what goes in the select() function?\n",
    "predictions.select().show(25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the job execution is done, try evaluating on how we performed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"\", predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy = %s\" % (accuracy))\n",
    "print(\"Test Error = %s\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra: Use the confusion matrix to see the other metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql.types import FloatType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "preds_and_labels = predictions.select(['prediction','encoded']).withColumn('encoded', F.col('encoded').cast(FloatType())).orderBy('prediction')\n",
    "preds_and_labels = preds_and_labels.select(['prediction','encoded'])\n",
    "metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "print(metrics.confusionMatrix().toArray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
